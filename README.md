# ğŸ¤– Autonomous Mobile Robot (AMR)
### ROS 2 Jazzy | Real-Time Perception | Embedded Control | Edge AI

An end-to-end **Autonomous Mobile Robot (AMR)** platform developed as a Mechatronics Engineering Graduation Project (2026).

This project integrates real-time perception, sensor fusion, embedded motor control, SLAM, and autonomous navigation into a complete robotic system designed using ROS 2 Jazzy best practices.

---

You can visit the official project website for more details: [https://delivero.site/](https://delivero.site/)

---

## ğŸ¥ Demonstration

Mapping Demo: [link](https://www.youtube.com/shorts/1S7ldnf2kuI)

Autonomous Navigation Demo: [link](https://youtu.be/pdu4tVg_QxQ?si=NQ7DHxntDtQeoHpF)

Real-World Robot Demo [link](https://www.youtube.com/shorts/1S7ldnf2kuI)

---

# ğŸ—ï¸ System Architecture


| Sensor / Input        | Processing Node / Algorithm      | Output Topic / Interface                                |
|----------------------|---------------------------------|--------------------------------------------------------|
| Camera               | Perception Node (TensorRT)      | `/detections`                                         |
| LiDAR                | SLAM Toolbox                    | `/map`                                                |
| Encoders + IMU       | EKF (Extended Kalman Filter)    | `/odom`                                               |
| Navigation (Nav2)    | Path Planner / Controller       | `/cmd_vel` â†’ micro-ROS (ESP32) â†’ Motor Driver â†’ Wheels |

The system is modular and scalable, separating hardware drivers, robot description, and system integration layers.

---

# ğŸ§  Real-Time Perception Pipeline

The robot integrates an optimized deep learning perception system:

- Model: YOLOv11n
- Framework: PyTorch â†’ ONNX â†’ TensorRT
- Precision: INT8, FP32
- Deployment: Custom ROS 2 inference node
- Output Topic: `/detections`

## ğŸ“Š Inference Performance (Edge Deployment)

| Mode  | FPS | Latency | Hardware |
|-------|-----|----------|----------|
| FP32  | 4â€“6  FPS  | 160â€“250 ms | Raspberry Pi 5 |
| INT8  | 12â€“18 FPS | 55â€“85 ms   | Raspberry Pi 5 |

Measured on CPU-only deployment, actual FPS may improve with GPU/Edge Accelerator

---

# ğŸ§­ Localization & Sensor Fusion

Localization is implemented using `robot_localization` (EKF):

- IMU + Wheel Encoder fusion
- REP-105 compliant TF tree:


map â†’ odom â†’ base_link


## ğŸ“Š EKF & Control Performance

- EKF update rate: <XX Hz>
- Control loop frequency: <XX Hz>
- Odometry drift: <XX% over XX meters>
- Maximum linear velocity: <XX m/s>
- Maximum angular velocity: <XX rad/s>

---

# ğŸ›°ï¸ Navigation Stack

- SLAM Toolbox for real-time mapping
- Navigation2 (Nav2) for path planning
- Dynamic obstacle avoidance
- Waypoint navigation support

## Autonomous Capabilities

- âœ… Mapping
- âœ… Localization
- âœ… Path planning
- âœ… Obstacle avoidance

---

# ğŸ”Œ Embedded & Low-Level Control

Low-level control handled via:

- ESP32 running micro-ROS
- Serial communication (`/dev/esp32`)
- Encoder feedback at <XX Hz>
- Closed-loop motor control

## Communication Metrics

- micro-ROS latency: <XX ms average>
- Serial baud rate: <XXXXXX>
- Motor response delay: <XX ms>

---

# ğŸ› ï¸ Hardware Stack

| Component | Model |
|------------|--------|
| LiDAR | LD06 |
| Camera | Orbbec Astra Pro |
| MCU | ESP32 S3 |
| Main Compute | Raspberry Pi 5 |
| Motor Driver | BTS7960 |
| Battery | 24V |

---

# ğŸ“Š System Resource Usage

Measured during full operation:

| Metric | Value |
|--------|--------|
| CPU Usage | 70â€“85% average |
| RAM Usage | 1.5â€“2.0 GB|
| Power Consumption | 12â€“15 W |
| Runtime per charge | 10â€“15 hours |

---

# ğŸ“‚ Repository Structure


AMR_Robot/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ hardware/ # Drivers & Communication
â”‚ â”œâ”€â”€ my_robot_description/ # URDF & TF definitions
â”‚ â””â”€â”€ robot_bringup/ # System integration & launch


The architecture follows a clear separation of concerns to ensure maintainability and scalability.

---

# ğŸš€ Build & Deployment

## 1ï¸âƒ£ Setup Device Rules

```bash
bash robot_bringup/scripts/setup_rules.sh
```

## 2ï¸âƒ£ Build Workspace
```bash
colcon build --symlink-install
source install/setup.bash
```

3ï¸âƒ£ Launch Robot
```bash
start_robot
```

## ğŸ§  Engineering Highlights

```
This project demonstrates:

End-to-end robotics system integration

Real-time AI deployment on edge hardware

ROS 2 modular architecture design

Embedded systems integration via micro-ROS

Performance optimization under hardware constraints

Production-oriented robotics engineering practices
```
---
